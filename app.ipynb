{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, jsonify, session\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'your_secret_key'  # Replace 'your_secret_key' with a real secret key\n",
    "\n",
    "# Configuration for file uploads\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "ALLOWED_EXTENSIONS = {'pdf'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Implement your logic here to use extracted_text and query to generate a response\n",
    "def answer_query(extracted_text, query):\n",
    "    # from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    from langchain.text_splitter import CharacterTextSplitter\n",
    "    from langchain.vectorstores import FAISS\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    \n",
    "    # Download embeddings from OpenAI\n",
    "    import os\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # We need to split the text using Character Text Split such that it sshould not increase token size\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator = \"\\n\",\n",
    "        chunk_size = 800,\n",
    "        chunk_overlap  = 200,\n",
    "        length_function = len,\n",
    "    )\n",
    "    texts = text_splitter.split_text(extracted_text)\n",
    "    print(len(texts))\n",
    "    document_search = FAISS.from_texts(texts, embeddings)\n",
    "    print(document_search)\n",
    "    \n",
    "    from langchain.chains.question_answering import load_qa_chain\n",
    "    from langchain.llms import OpenAI\n",
    "    \n",
    "    chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
    "#     query = \"What is the topic of this document?\"\n",
    "    docs = document_search.similarity_search(query)\n",
    "    response = chain.run(input_documents=docs, question=query)\n",
    "    return response\n",
    "    \n",
    "    \n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "    file = request.files['file']\n",
    "    if file.filename == '' or not allowed_file(file.filename):\n",
    "        return jsonify({'error': 'No selected file or file type not allowed'}), 400\n",
    "    \n",
    "    filename = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "    file.save(filename)\n",
    "    extracted_text = extract_text_from_pdf(filename)\n",
    "    session['extracted_text'] = extracted_text\n",
    "    return jsonify({'message': 'File successfully uploaded'}), 200\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def handle_query():\n",
    "    query = request.json.get('query', '')\n",
    "    if not query or 'extracted_text' not in session:\n",
    "        return jsonify({'error': 'Empty query or no document uploaded'}), 400\n",
    "    extracted_text = session['extracted_text']\n",
    "    response = answer_query(extracted_text, query)\n",
    "    return jsonify({'answer': response}), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if not os.path.exists(UPLOAD_FOLDER):\n",
    "        os.makedirs(UPLOAD_FOLDER)\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
